import torch
import torch.nn.functional as F
import torchvision.datasets as datasets
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import torch.optim as optim
from torch import nn
from tqdm import tqdm


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

train_data = datasets.MNIST(root = 'data',train = True,transform = transforms.ToTensor(), download = True)

test_data = datasets.MNIST(root = 'data',train = False, download = True,transform = transforms.ToTensor())

batch_size = 64

train_loader = DataLoader(train_data,batch_size,shuffle=True)
test_loader = DataLoader(test_data,batch_size,shuffle=True)

class CNN(nn.Module):
  def __init__(self, in_channels=1, num_classes=10):
    super(CNN,self).__init__()
    self.convl1 = nn.Conv2d(in_channels=1,out_channels=32,kernel_size=3,stride=1,padding=1)
    self.pool = nn.MaxPool2d(kernel_size=2,stride=2)
    self.convl2 = nn.Conv2d(in_channels=32,out_channels=16,kernel_size=3,stride=1,padding=1)
    self.fc1 = nn.Linear(16*7*7,128)
    self.fc2 = nn.Linear(128,num_classes)
  def forward(self,x):
    x = F.relu(self.convl1(x))
    x = self.pool(x)
    x = F.relu(self.convl2(x))
    x = self.pool(x)  
    x = x.reshape(x.shape[0],-1)
    x = self.fc1(x)
    x = self.fc2(x)
    return x

model = CNN().to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(),lr=0.001)

num_epoch = 10

def accuracy(pred,target):
  correct = torch.eq(pred,target).sum().item()
  acc = (correct/len(target))*100
  return acc

def train_model(model,train_loader,num_epoch,criterion,optimizer,device):
  
  model.train()
  total_preds = []
  total_targets = []


  for batch_indx ,(data,targets) in enumerate(train_loader):
    data = data.to(device)
    targets = targets.to(device)

    pred_score = model(data)

    train_loss = criterion(pred_score,targets)
    optimizer.zero_grad()
    train_loss.backward()
    optimizer.step()

    pred = pred_score.argmax(dim = 1, keepdim = False) 
    total_preds.extend(pred.cpu())
    total_targets.extend(targets.cpu())

    if batch_indx % 100 == 0:
      batch_accuracy = accuracy(torch.tensor(total_targets), torch.tensor(total_preds))
      print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}\tAccuracy: {:.2f}%'.format(
                epoch+1, batch_indx * len(data), len(train_loader.dataset),
                100. * batch_indx / len(train_loader), train_loss.item(), batch_accuracy))
      total_preds.clear()  
      total_targets.clear()
  
def test_model(model,test_loader,criterion,device):
  
  model.eval()
  total_preds = []
  total_targets = []    
  test_loss = 0

  with torch.no_grad():
    for batch_indx ,(data,targets) in enumerate(test_loader):
      data = data.to(device)
      targets = targets.to(device)

      pred_score = model(data)

      test_loss += criterion(pred_score,targets).item()
      pred = pred_score.argmax(dim = 1, keepdim = False) 
      total_preds.extend(pred.cpu())
      total_targets.extend(targets.cpu())


    test_loss /= len(test_loader.dataset)
    acc = accuracy(torch.tensor(total_targets), torch.tensor(total_preds))
    print('\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\n'.format(
        test_loss, len(total_preds), len(test_loader.dataset),
        acc))
    total_preds.clear()  
    total_targets.clear()

for epoch in range(num_epoch):
  train_model(model,train_loader,num_epoch,criterion,optimizer,device)
  test_model(model,test_loader,criterion,device)
